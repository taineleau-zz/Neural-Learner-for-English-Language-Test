Train on 23850 samples, validate on 5962 samples
Epoch 1/100
23850/23850 [==============================] - 59s - loss: 26.7667 - acc: 0.0498 - val_loss: 27.7682 - val_acc: 0.0174
Epoch 2/100
23850/23850 [==============================] - 59s - loss: 22.6457 - acc: 0.1237 - val_loss: 29.3200 - val_acc: 0.0413
Epoch 3/100
23850/23850 [==============================] - 60s - loss: 20.5607 - acc: 0.1594 - val_loss: 30.3465 - val_acc: 0.0406
Epoch 4/100
23850/23850 [==============================] - 60s - loss: 19.6971 - acc: 0.1722 - val_loss: 30.4473 - val_acc: 0.0649
Epoch 5/100
23850/23850 [==============================] - 60s - loss: 19.2009 - acc: 0.1829 - val_loss: 30.7740 - val_acc: 0.0679
Epoch 6/100
23850/23850 [==============================] - 60s - loss: 18.8688 - acc: 0.1816 - val_loss: 30.8773 - val_acc: 0.0543
Epoch 7/100
23850/23850 [==============================] - 60s - loss: 18.5902 - acc: 0.1827 - val_loss: 31.0104 - val_acc: 0.0775
Epoch 8/100
23850/23850 [==============================] - 60s - loss: 18.3705 - acc: 0.1837 - val_loss: 31.2660 - val_acc: 0.0585
Epoch 9/100
23850/23850 [==============================] - 60s - loss: 18.1798 - acc: 0.1837 - val_loss: 31.3460 - val_acc: 0.0609
Epoch 10/100
23850/23850 [==============================] - 60s - loss: 17.9993 - acc: 0.1854 - val_loss: 31.6194 - val_acc: 0.0715
Epoch 11/100
23850/23850 [==============================] - 60s - loss: 17.8604 - acc: 0.1824 - val_loss: 31.6835 - val_acc: 0.0631
Epoch 12/100
23850/23850 [==============================] - 60s - loss: 17.7137 - acc: 0.1877 - val_loss: 32.0697 - val_acc: 0.0661
Epoch 13/100
23850/23850 [==============================] - 60s - loss: 17.5730 - acc: 0.1836 - val_loss: 31.9861 - val_acc: 0.0713
Epoch 14/100
23850/23850 [==============================] - 60s - loss: 17.4518 - acc: 0.1845 - val_loss: 32.5135 - val_acc: 0.0644
Epoch 15/100
23850/23850 [==============================] - 61s - loss: 17.3411 - acc: 0.1873 - val_loss: 32.8059 - val_acc: 0.0575
Epoch 16/100
23850/23850 [==============================] - 60s - loss: 17.2285 - acc: 0.1851 - val_loss: 33.3482 - val_acc: 0.0641
Epoch 17/100
23850/23850 [==============================] - 60s - loss: 17.1267 - acc: 0.1868 - val_loss: 33.6221 - val_acc: 0.0709
Epoch 18/100
23850/23850 [==============================] - 60s - loss: 17.0423 - acc: 0.1859 - val_loss: 34.3286 - val_acc: 0.0679
Epoch 19/100
23850/23850 [==============================] - 61s - loss: 16.9439 - acc: 0.1890 - val_loss: 34.4326 - val_acc: 0.0840
Epoch 20/100
23850/23850 [==============================] - 60s - loss: 16.8646 - acc: 0.1854 - val_loss: 35.2396 - val_acc: 0.0785
Epoch 21/100
23850/23850 [==============================] - 60s - loss: 16.7931 - acc: 0.1855 - val_loss: 35.4368 - val_acc: 0.0678
Epoch 22/100
23850/23850 [==============================] - 60s - loss: 16.7175 - acc: 0.1865 - val_loss: 36.5760 - val_acc: 0.0746
Epoch 23/100
23850/23850 [==============================] - 60s - loss: 16.6498 - acc: 0.1836 - val_loss: 36.9333 - val_acc: 0.0782
Epoch 24/100
23850/23850 [==============================] - 60s - loss: 16.5928 - acc: 0.1867 - val_loss: 37.4427 - val_acc: 0.0800
Epoch 25/100
23850/23850 [==============================] - 60s - loss: 16.5233 - acc: 0.1842 - val_loss: 38.0346 - val_acc: 0.0745
Epoch 26/100
23850/23850 [==============================] - 61s - loss: 16.4698 - acc: 0.1850 - val_loss: 38.9463 - val_acc: 0.0897
Epoch 27/100
23850/23850 [==============================] - 60s - loss: 16.4143 - acc: 0.1853 - val_loss: 39.0511 - val_acc: 0.0810
Epoch 28/100
23850/23850 [==============================] - 61s - loss: 16.3547 - acc: 0.1866 - val_loss: 39.6764 - val_acc: 0.0845
Epoch 29/100
23850/23850 [==============================] - 61s - loss: 16.3096 - acc: 0.1860 - val_loss: 40.4968 - val_acc: 0.0696
Epoch 30/100
23850/23850 [==============================] - 62s - loss: 16.2684 - acc: 0.1808 - val_loss: 41.0141 - val_acc: 0.0897
Epoch 31/100
23850/23850 [==============================] - 60s - loss: 16.2197 - acc: 0.1861 - val_loss: 42.8357 - val_acc: 0.0701
Epoch 32/100
23850/23850 [==============================] - 60s - loss: 16.1810 - acc: 0.1800 - val_loss: 43.5656 - val_acc: 0.0805
Epoch 33/100
23850/23850 [==============================] - 60s - loss: 16.1382 - acc: 0.1857 - val_loss: 43.7726 - val_acc: 0.0728
Epoch 34/100
23850/23850 [==============================] - 61s - loss: 16.1121 - acc: 0.1806 - val_loss: 44.0682 - val_acc: 0.0698
Epoch 35/100
23850/23850 [==============================] - 60s - loss: 16.0637 - acc: 0.1815 - val_loss: 45.2072 - val_acc: 0.0713
Epoch 36/100
23850/23850 [==============================] - 60s - loss: 16.0308 - acc: 0.1835 - val_loss: 45.5033 - val_acc: 0.0835
Epoch 37/100
23850/23850 [==============================] - 60s - loss: 15.9971 - acc: 0.1849 - val_loss: 46.0869 - val_acc: 0.0867
Epoch 38/100
23850/23850 [==============================] - 60s - loss: 15.9759 - acc: 0.1830 - val_loss: 48.2428 - val_acc: 0.0735
Epoch 39/100
23850/23850 [==============================] - 60s - loss: 15.9441 - acc: 0.1817 - val_loss: 47.8063 - val_acc: 0.0696
Epoch 40/100
23850/23850 [==============================] - 60s - loss: 15.9248 - acc: 0.1812 - val_loss: 47.7709 - val_acc: 0.0923
Epoch 41/100
23850/23850 [==============================] - 60s - loss: 15.8937 - acc: 0.1781 - val_loss: 48.5354 - val_acc: 0.0731
Epoch 42/100
23850/23850 [==============================] - 60s - loss: 15.8656 - acc: 0.1801 - val_loss: 49.3794 - val_acc: 0.0746
Epoch 43/100
23850/23850 [==============================] - 60s - loss: 15.8505 - acc: 0.1776 - val_loss: 50.5218 - val_acc: 0.0686
Epoch 44/100
23850/23850 [==============================] - 60s - loss: 15.8220 - acc: 0.1834 - val_loss: 50.1574 - val_acc: 0.0721
Epoch 45/100
23850/23850 [==============================] - 60s - loss: 15.8110 - acc: 0.1794 - val_loss: 50.8134 - val_acc: 0.0679
Epoch 46/100
23850/23850 [==============================] - 60s - loss: 15.7904 - acc: 0.1841 - val_loss: 53.1350 - val_acc: 0.0535
Epoch 47/100
23850/23850 [==============================] - 60s - loss: 15.7749 - acc: 0.1846 - val_loss: 51.6462 - val_acc: 0.0798
Epoch 48/100
23850/23850 [==============================] - 60s - loss: 15.7497 - acc: 0.1800 - val_loss: 53.7400 - val_acc: 0.0798
Epoch 49/100
23850/23850 [==============================] - 60s - loss: 15.7518 - acc: 0.1813 - val_loss: 52.9741 - val_acc: 0.0704
Epoch 50/100
23850/23850 [==============================] - 60s - loss: 15.7386 - acc: 0.1840 - val_loss: 53.6593 - val_acc: 0.0951


训了50个epoch，准确率9.51%



Train on 265192 samples, validate on 66299 samples
Epoch 1/20
265192/265192 [==============================] - 156s - loss: 4.0081 - acc: 0.3046 - val_loss: 3.3758 - val_acc: 0.3516
Epoch 2/20
265192/265192 [==============================] - 151s - loss: 3.7801 - acc: 0.3700 - val_loss: 3.2654 - val_acc: 0.3801
Epoch 3/20
265192/265192 [==============================] - 150s - loss: 3.6696 - acc: 0.4075 - val_loss: 3.2267 - val_acc: 0.3954
Epoch 4/20
265192/265192 [==============================] - 151s - loss: 3.5873 - acc: 0.4380 - val_loss: 3.2025 - val_acc: 0.4065
Epoch 5/20
265192/265192 [==============================] - 150s - loss: 3.5266 - acc: 0.4600 - val_loss: 3.1889 - val_acc: 0.4124
Epoch 6/20
265192/265192 [==============================] - 147s - loss: 3.4789 - acc: 0.4754 - val_loss: 3.1798 - val_acc: 0.4134
Epoch 7/20
265192/265192 [==============================] - 158s - loss: 3.4386 - acc: 0.4863 - val_loss: 3.1770 - val_acc: 0.4122
Epoch 8/20
265192/265192 [==============================] - 148s - loss: 3.4050 - acc: 0.4954 - val_loss: 3.1637 - val_acc: 0.4140
Epoch 9/20
265192/265192 [==============================] - 145s - loss: 3.3734 - acc: 0.5038 - val_loss: 3.1852 - val_acc: 0.4126
Epoch 10/20
265192/265192 [==============================] - 149s - loss: 3.3474 - acc: 0.5108 - val_loss: 3.1867 - val_acc: 0.4102


准确率41.3%, l1 = 0.02


朴素贝叶斯（wh）：
42644
0.360624604347


Epoch 1/10
36704/36704 [==============================] - 37s - loss: 3.4899 - acc: 0.2024 - val_loss: 2.8647 - val_acc: 0.2686
Epoch 2/10
36704/36704 [==============================] - 37s - loss: 3.0488 - acc: 0.3092 - val_loss: 2.5566 - val_acc: 0.3544
Epoch 3/10
36704/36704 [==============================] - 36s - loss: 2.8194 - acc: 0.3941 - val_loss: 2.4366 - val_acc: 0.3764
Epoch 4/10
36704/36704 [==============================] - 36s - loss: 2.7157 - acc: 0.4319 - val_loss: 2.4212 - val_acc: 0.3828
Epoch 5/10
36704/36704 [==============================] - 36s - loss: 2.6304 - acc: 0.4654 - val_loss: 2.4153 - val_acc: 0.3887
Epoch 6/10
36704/36704 [==============================] - 37s - loss: 2.5757 - acc: 0.4932 - val_loss: 2.4317 - val_acc: 0.3802
Epoch 7/10
36704/36704 [==============================] - 36s - loss: 2.5261 - acc: 0.5126 - val_loss: 2.4301 - val_acc: 0.3781
Epoch 8/10
36704/36704 [==============================] - 37s - loss: 2.4874 - acc: 0.5300 - val_loss: 2.4548 - val_acc: 0.3751
Epoch 9/10
36704/36704 [==============================] - 37s - loss: 2.4553 - acc: 0.5465 - val_loss: 2.4631 - val_acc: 0.3798
Epoch 10/10
36704/36704 [==============================] - 37s - loss: 2.4196 - acc: 0.5627 - val_loss: 2.4597 - val_acc: 0.3779
9177/9177 [==============================] - 1s
Test score: 2.45971932322
Test accuracy: 0.377901274926

最大熵分类器
dlchen@debian-fnlp-server ~/nlpPJ % python classifier.py
10213
  ==> Training (10 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -4.88280        0.000
             2          -1.94166        0.706
             3          -1.10977        0.784
             4          -0.81231        0.831
             5          -0.65904        0.861
             6          -0.56397        0.880
             7          -0.49856        0.896
             8          -0.45057        0.906
             9          -0.41373        0.914
         Final          -0.38449        0.919
0.325110132159

MLP-失败

23850 train sequences
5962 test sequences
Pad sequences (samples x time)
X_train shape: (23850, 50)
X_test shape: (5962, 50)
Build model...
Train...
Train on 23850 samples, validate on 5962 samples
Epoch 1/20
23850/23850 [==============================] - 45s - loss: 36.0584 - acc: 0.0132 - val_loss: 32.3809 - val_acc: 0.0013
Epoch 2/20
23850/23850 [==============================] - 45s - loss: 32.7312 - acc: 0.0024 - val_loss: 31.7333 - val_acc: 0.0013
Epoch 3/20
23850/23850 [==============================] - 47s - loss: 31.9406 - acc: 0.0024 - val_loss: 30.8503 - val_acc: 0.0013
Epoch 4/20
23850/23850 [==============================] - 45s - loss: 31.2285 - acc: 0.0024 - val_loss: 30.3432 - val_acc: 0.0013
Epoch 5/20
23850/23850 [==============================] - 46s - loss: 30.9416 - acc: 0.0024 - val_loss: 30.3564 - val_acc: 0.0013
Epoch 6/20
23850/23850 [==============================] - 46s - loss: 30.9089 - acc: 0.0024 - val_loss: 30.3242 - val_acc: 0.0013
Epoch 7/20
23850/23850 [==============================] - 46s - loss: 30.8579 - acc: 0.0024 - val_loss: 30.3025 - val_acc: 0.0013
Epoch 8/20
23850/23850 [==============================] - 46s - loss: 30.8284 - acc: 0.0024 - val_loss: 30.3122 - val_acc: 0.0013
Epoch 9/20
23850/23850 [==============================] - 45s - loss: 30.8111 - acc: 0.0024 - val_loss: 30.3413 - val_acc: 0.0013
Epoch 10/20
23850/23850 [==============================] - 45s - loss: 30.8771 - acc: 0.0024 - val_loss: 30.3293 - val_acc: 0.0013
Epoch 11/20
23850/23850 [==============================] - 46s - loss: 30.6630 - acc: 0.0024 - val_loss: 30.5728 - val_acc: 0.0013
Epoch 12/20
23850/23850 [==============================] - 45s - loss: 30.2944 - acc: 0.0024 - val_loss: 31.3756 - val_acc: 0.0013
Epoch 13/20
23850/23850 [==============================] - 45s - loss: 30.0657 - acc: 0.0025 - val_loss: 32.8713 - val_acc: 0.0013
Epoch 14/20
23850/23850 [==============================] - 46s - loss: 29.7250 - acc: 0.0029 - val_loss: 34.3883 - val_acc: 0.0013
Epoch 15/20
23850/23850 [==============================] - 46s - loss: 29.5307 - acc: 0.0029 - val_loss: 35.1301 - val_acc: 0.0013
Epoch 16/20
23850/23850 [==============================] - 45s - loss: 29.1807 - acc: 0.0034 - val_loss: 36.9403 - val_acc: 0.0013
Epoch 17/20
23850/23850 [==============================] - 45s - loss: 29.2112 - acc: 0.0039 - val_loss: 36.8282 - val_acc: 0.0013
Epoch 18/20
23850/23850 [==============================] - 45s - loss: 28.7648 - acc: 0.0052 - val_loss: 36.8307 - val_acc: 0.0013
Epoch 19/20
23850/23850 [==============================] - 46s - loss: 28.7207 - acc: 0.0063 - val_loss: 36.7611 - val_acc: 0.0013
Epoch 20/20
23850/23850 [==============================] - 45s - loss: 28.5408 - acc: 0.0088 - val_loss: 38.8277 - val_acc: 0.0013
5962/5962 [==============================] - 2s
Test score: 38.8276538401
Test accuracy: 0.00134183160013